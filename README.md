# ğŸ¤– Chat Assistant con React + TanStack Query

Este proyecto implementa una interfaz de chat con un modelo de lenguaje (LLM).  
Permite enviar mensajes al backend y configurar parÃ¡metros avanzados de inferencia como **temperature, top-k, top-p y reasoning effort**.

## ğŸš€ TecnologÃ­as
- [React](https://react.dev/) â€“ interfaz de usuario
- [TypeScript](https://www.typescriptlang.org/) â€“ tipado estÃ¡tico
- [TanStack Query](https://tanstack.com/query/latest) â€“ manejo de mutaciones y peticiones
- [Tailwind CSS](https://tailwindcss.com/) â€“ estilos rÃ¡pidos y responsivos

---

## ğŸ“‚ Estructura bÃ¡sica
```

src/
â”œâ”€ components/
â”‚   â””â”€ ChatInterface.tsx   # UI principal del chat
â”œâ”€ index.tsx               # punto de entrada
â””â”€ ...

```

---

## âš™ï¸ ParÃ¡metros configurables

El formulario en la parte inferior del chat permite definir los siguientes valores antes de enviar un mensaje:

| ParÃ¡metro           | Rango       | DescripciÃ³n |
|---------------------|------------|-------------|
| `temperature`       | 0 â€“ 2      | Controla la aleatoriedad. Valores bajos hacen la salida mÃ¡s determinista. |
| `top-k`             | 0 â€“ 20     | Limita el muestreo a los *k* tokens mÃ¡s probables. |
| `top-p`             | 0 â€“ 1      | Usa *nucleus sampling*, limitando al conjunto acumulativo de probabilidad *p*. |
| `reasoning_effort`  | 1 â€“ 4      | Nivel de esfuerzo de razonamiento. **Se envÃ­a como nÃºmero**:<br> `1 = minimal`, `2 = low`, `3 = medium`, `4 = high`. |

âš ï¸ **Importante:**  
Solo puede usarse `top-k` **o** `top-p`, nunca ambos.  
Si se define uno, el otro se desactiva automÃ¡ticamente.

---

## ğŸ“¡ ComunicaciÃ³n con el API

Las peticiones al backend se envÃ­an vÃ­a `fetch` a la ruta:

```

POST [https://llm-bootcamp.cardor.dev/api/completion](https://llm-bootcamp.cardor.dev/api/completion)

````

### Ejemplo de body:
```json
{
  "input": "Â¿CuÃ¡l es la capital de Ecuador?",
  "params": {
    "temperature": 1,
    "top_k": 10,
    "reasoning_effort": 2
  }
}
````

---

## â–¶ï¸ EjecuciÃ³n local

1. Clona el repositorio:

   ```bash
   git clone https://github.com/admolinac/llm-chat-project
   cd llm-chat-project
   ```

2. Instala dependencias:

   ```bash
   npm install
   ```

3. Corre en modo desarrollo:

   ```bash
   npm run dev
   ```

4. Abre en tu navegador:

   ```
   http://localhost:3000
   ```


ğŸ‘‰ Â¿Quieres que en el `README` tambiÃ©n deje un **mapa de correspondencia de parÃ¡metros (ejemplo de UI â†’ valor numÃ©rico final en el request)** para que quede clarÃ­simo cÃ³mo pasa de select a nÃºmero?
```
